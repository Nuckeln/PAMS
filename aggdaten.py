# -*- coding: utf-8 -*-
"""AggDaten.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zocc3kriZHFV5MvyU80GKrOpQfj8AK7w

#Terminal Comand to convert in Py
jupyter nbconvert --to script AggDaten.ipynb
"""
import datetime
import pandas as pd
import numpy as np
from src.SQL import SQL_TabellenLadenBearbeiten as SQL
import time
import src.AzureStorage as AzureStorage
from src.SQL_Neu import save_table_to_SQL



def agg_stammdatenErweiterung(dfStammdaten)-> pd.DataFrame:
    '''
    return Stammdaten mit den Spalten CS, PAL, OUT
    lädt die Stammdatentabelle aus der DB und berechnet Nummerator und Denominator gibt aggrigierte Daten aus und speichert diese in einer Parquet Datei
    '''
    if len(dfStammdaten) > 10:
        dfStammdaten.to_parquet('appdata/dfStammdaten.parquet')
    else:
        ''
        print('Stammdaten zu kurz')
        dfStammdaten = pd.read_parquet('appdata/dfStammdaten.parquet')   
    dfStammdaten = dfStammdaten[dfStammdaten['UnitOfMeasure'].isin(['CS','D97','OUT'])]
    dfStammdaten['MaterialNumber'] = dfStammdaten['MaterialNumber'].str.replace('0000000000', '')
    def f_CS(row):
        try:
            if row.UnitOfMeasure == 'CS':          
                return row.NumeratorToBaseUnitOfMeasure / row.DenominatorToBaseUnitOfMeasure
        except:
            return np.nan
    def f_PAL(row):
        try:
            if row.UnitOfMeasure == 'D97':
                return row.NumeratorToBaseUnitOfMeasure / row.DenominatorToBaseUnitOfMeasure
        except:
            return np.nan
    def f_OUT(row):
        try:
            if row.UnitOfMeasure == 'OUT':
                return row.NumeratorToBaseUnitOfMeasure / row.DenominatorToBaseUnitOfMeasure
        except:
            return np.nan
    dfStammdaten['OUT'] = dfStammdaten.apply(f_OUT,axis=1)
    dfStammdaten['CS'] = dfStammdaten.apply(f_CS,axis=1)
    dfStammdaten['PAL'] = dfStammdaten.apply(f_PAL,axis=1)
    #safe dfSammdaten to excel
    #safe df to parquet file
    dfStammdaten.to_parquet('appdata/dfStammdaten.parquet')
    return dfStammdaten

def agg_berechne_DFOrderItems(dfOrderItems: pd.DataFrame, dfStammdaten: pd.DataFrame, dfOrder: pd.DataFrame)-> pd.DataFrame:

    ##------------------ Kunden von DB Laden ------------------##
    dfKunden = SQL.sql_datenTabelleLaden('Kunden_mit_Packinfos')
    ##------------------ Merge Items und Stammdaten ------------------##
    dfOrderItems['MaterialNumber'] = dfOrderItems['MaterialNumber'].astype(str)
    dfOrderItems['MaterialNumber'] = dfOrderItems['MaterialNumber'].str.replace('0000000000', '')
    dfOrderItems = pd.merge(dfOrderItems, dfStammdaten[dfStammdaten['UnitOfMeasure'] == 'CS'][['MaterialNumber','CS']],left_on='MaterialNumber', right_on='MaterialNumber',how='left')
    dfOrderItems = pd.merge(dfOrderItems, dfStammdaten[dfStammdaten['UnitOfMeasure'] == 'D97'][['MaterialNumber','PAL']],left_on='MaterialNumber', right_on='MaterialNumber',how='left')
    dfOrderItems = pd.merge(dfOrderItems, dfStammdaten[dfStammdaten['UnitOfMeasure'] == 'OUT'][['MaterialNumber','OUT']],left_on='MaterialNumber', right_on='MaterialNumber',how='left')

    dfOrderItems['VolInThKg'] = dfOrderItems['Outers'] * dfOrderItems['OUT']
    dfOrderItems['PicksPAL'] = dfOrderItems.VolInThKg / dfOrderItems.PAL
    dfOrderItems['PicksCS'] = dfOrderItems.CorrespondingCartons 
    dfOrderItems['Picks OUT'] = dfOrderItems.CorrespondingOuters
    #Bereinige Berechnungen der Picks 
    dfOrderItems['PicksPAL'] = dfOrderItems['PicksPAL'].fillna(0) 
    dfOrderItems['VolInThKg'] = dfOrderItems.VolInThKg.fillna(0) 
    dfOrderItems['Picks OUT'] = dfOrderItems['Picks OUT'].fillna(0) 

    # Pal kleiner als 1 bereinigen
    def f_PAL(row):
            if row.PicksPAL < 1:
                return 0
            else:
                return row.PicksPAL

    dfOrderItems['PicksPAL'] = dfOrderItems.apply(f_PAL,axis=1)

    def f_OUT(row):
            if row.PicksPAL >= 1:
                return row.CorrespondingCartons  - ((row.PicksPAL * row.PAL) / row.CS)
            else:
                return row.CorrespondingCartons

    dfOrderItems['Picks CS'] = dfOrderItems.apply(f_OUT,axis=1)
    #rename column PicksPAL to Picks PAL
    dfOrderItems = dfOrderItems.rename(columns={'PicksPAL': 'Picks PAL'})

    dfOrderItems['Picks Gesamt'] = dfOrderItems['Picks PAL'] + dfOrderItems['Picks CS'] + dfOrderItems['Picks OUT']
    #dfKunden PartnerNo to string
    dfKunden['PartnerNo'] = dfKunden['PartnerNo'].astype(str)

    # applying merge

    df = pd.merge(dfOrder, dfOrderItems, left_on='SapOrderNumber', right_on='SapOrderNumber', how='left')
    df = pd.merge(df, dfKunden[['PartnerNo', 'PartnerName']], on='PartnerNo', how='left')


    df['PicksGesamt'] = df['Picks Gesamt']

    def f_Fertig(row):
        try:
            if row.AllSSCCLabelsPrinted == 1:
                return row.PicksGesamt
        except:
            return np.nan
    df['PicksFertig'] = df.apply(f_Fertig,axis=1)
    def f_Offen(row):
        try:
            if row.AllSSCCLabelsPrinted == 0:
                return row.PicksGesamt
        except:
            return np.nan
    df['PicksOffen'] = df.apply(f_Offen,axis=1)

    #drop row frow df if isReturnDelivery = 1
    # convert  IDocNumberDESADV to string
    df['IDocNumberDESADV'] = df['IDocNumberDESADV'].astype(str)

    df = df[df['IsReturnDelivery'] == 0]
    df = df.fillna(0)
    #df[QuantityCheckTimestamp to string
    df['QuantityCheckTimestamp'] = df['QuantityCheckTimestamp'].astype(str)
    df['Source'] = df['Source'].astype(str)
    df['UnloadingListIdentifier'] = df['UnloadingListIdentifier'].astype(str)
    #NiceLabelTransmissionState_TimeStamp to string
    df['NiceLabelTransmissionState_TimeStamp'] = df['NiceLabelTransmissionState_TimeStamp'].astype(str)
    #save to Database
    dfTabele = df
    # convert CreatedTimestamp to string
    dfTabele['CreatedTimestamp'] = dfTabele['CreatedTimestamp'].astype(str)
    # convert PlannedDate to string
    dfTabele['PlannedDate'] = dfTabele['PlannedDate'].astype(str)
    # convert QuantityCheckTimestamp to string
    dfTabele['QuantityCheckTimestamp'] = dfTabele['QuantityCheckTimestamp'].astype(str)
    # convert NiceLabelTransmissionState_TimeStamp to string
    dfTabele['NiceLabelTransmissionState_TimeStamp'] = dfTabele['NiceLabelTransmissionState_TimeStamp'].astype(str)
    # convert UpdatedTimestamp to string
    dfTabele['UpdatedTimestamp'] = dfTabele['UpdatedTimestamp'].astype(str)

    #convert dfTable to pickle
    dfTabele.to_csv('dfTabele.csv')
    file = open('dfTabele.csv', 'rb')
    
    #upload to Azure
    AzureStorage.upload_file_to_blob_storage_with_orgName('dfTabele.csv',file,'DatenAgregieren')
    #SQL.sql_updateTabelle('OrderDatenLines',dfTabele)
    return df

def agg_oderDatenItemsAndLabel(dfOrderItems,dfLabel):
    df = dfOrderItems.copy()
    df1 = df.copy()

    df = df.groupby(['PlannedDate','PartnerName','SapOrderNumber',"AllSSCCLabelsPrinted",'DeliveryDepot']).agg({'Picks Gesamt':'sum'}).reset_index()
    df1["QuantityCheckTimestamp"] = pd.to_datetime(df1["QuantityCheckTimestamp"], errors='coerce')
    df1['QuantityCheckTimestamp'] = df1['QuantityCheckTimestamp'].dt.strftime("%Y-%m-%d %H:%M:%S")
    df['Lieferschein erhalten'] = df1.loc[df1['SapOrderNumber'].isin(df['SapOrderNumber'])].groupby('SapOrderNumber')['CreatedTimestamp'].first().reindex(df['SapOrderNumber']).reset_index(name='Lieferschein erhalten')['Lieferschein erhalten']

    df['Fertiggestellt'] = df1.loc[df1['SapOrderNumber'].isin(df['SapOrderNumber']) & df1['QuantityCheckTimestamp'].notnull()].groupby('SapOrderNumber')['QuantityCheckTimestamp'].first().reindex(df['SapOrderNumber']).reset_index(name='Fertiggestellt')['Fertiggestellt']
    if df['Fertiggestellt'].notna().all():
        df['Fertiggestellt'] = pd.to_datetime(df['Fertiggestellt']) + pd.DateOffset(hours=2)
        df['Fertiggestellt'] = df['Fertiggestellt'].dt.strftime("%Y-%m-%d %H:%M:%S")

    df['Truck Kennzeichen'] = df1.loc[df1['SapOrderNumber'].isin(df['SapOrderNumber'])].groupby('SapOrderNumber')['UnloadingListIdentifier'].first().reindex(df['SapOrderNumber']).reset_index(name='Truck Kennzeichen')['Truck Kennzeichen']
    df['Picks Karton'] = df1.groupby('SapOrderNumber')['Picks CS'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Karton')['Picks Karton']
    df['Picks Paletten'] = df1.groupby('SapOrderNumber')['Picks PAL'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Paletten')['Picks Paletten']
    df['Picks Stangen'] = df1.groupby('SapOrderNumber')['Picks OUT'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Stangen')['Picks Stangen']
    df['Picks Karton offen'] = df1[(df1['AllSSCCLabelsPrinted'] == 0)].groupby('SapOrderNumber')['Picks CS'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Karton offen')['Picks Karton offen']
    df['Picks Paletten offen'] = df1[(df1['AllSSCCLabelsPrinted'] == 0)].groupby('SapOrderNumber')['Picks PAL'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Paletten offen')['Picks Paletten offen']
    df['Picks Stangen offen'] = df1[(df1['AllSSCCLabelsPrinted'] == 0)].groupby('SapOrderNumber')['Picks OUT'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Stangen offen')['Picks Stangen offen']
    df['Picks Karton fertig'] = df1[(df1['AllSSCCLabelsPrinted'] == 1)].groupby('SapOrderNumber')['Picks CS'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Karton fertig')['Picks Karton fertig']
    df['Picks Paletten fertig'] = df1[(df1['AllSSCCLabelsPrinted'] == 1)].groupby('SapOrderNumber')['Picks PAL'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Paletten fertig')['Picks Paletten fertig']
    df['Picks Stangen fertig'] = df1[(df1['AllSSCCLabelsPrinted'] == 1)].groupby('SapOrderNumber')['Picks OUT'].sum().reindex(df['SapOrderNumber']).reset_index(name='Picks Stangen fertig')['Picks Stangen fertig']

    df['PartnerName'] = df['PartnerName'].astype(str)
    df['SapOrderNumber'] = df['SapOrderNumber'].astype(str)
    df['Picks Gesamt'] = df['Picks Gesamt'].astype(int)
    df['Fertige Paletten'] = dfLabel[(dfLabel['UnitOfMeasure'] == 'D97') & (dfLabel['ParentID'].isnull()) & dfLabel['SapOrderNumber'].isin(df['SapOrderNumber'])].groupby('SapOrderNumber').size().reindex(df['SapOrderNumber']).reset_index(name='Fertige Paletten')['Fertige Paletten']
    df['Lieferschein erhalten'] = df['Lieferschein erhalten'].astype(str)
    df['Fertiggestellt'] = df['Fertiggestellt'].astype(str)
    df['Fertiggestellt'] = df['Fertiggestellt'].str.replace("nan","")
    df['Fertiggestellt'] = df['Fertiggestellt'].str.replace("NaT","")
    df['PlannedDate'] = df['PlannedDate'].astype(str)

    return df

def loadTablesFromDB_byDateAndFilterDN(start_date, end_date)-> pd.DataFrame:
    dfOrder = SQL.sql_datenLadenDatum(start_date,end_date,'business_depotDEBYKN-DepotDEBYKNOrders','PlannedDate')
    # new list with all uinique SapOrderNumber
    SapOrderNumberList = dfOrder.SapOrderNumber.unique()
    #convert to string and list
    SapOrderNumberList = SapOrderNumberList.astype(str)
    SapOrderNumberList = SapOrderNumberList.tolist()
    ##------------------ Order Items von DB Laden ------------------##
    dfOrderItems = SQL.load_table_by_order_number('business_depotDEBYKN-DepotDEBYKNOrderItems',SapOrderNumberList)
    #------------------ Stammdaten von DB Laden ------------------#
    dfStammdaten = SQL.sql_datenTabelleLaden('data_materialmaster-MaterialMasterUnitOfMeasures')
    return dfOrderItems, dfOrder, dfStammdaten

def loadAllDataFromDB()-> pd.DataFrame:
    dfOrder = SQL.sql_datenTabelleLaden('business_depotDEBYKN-DepotDEBYKNOrders')
    # new list with all uinique SapOrderNumber
    SapOrderNumberList = dfOrder.SapOrderNumber.unique()
    #convert to string and list
    SapOrderNumberList = SapOrderNumberList.astype(str)
    SapOrderNumberList = SapOrderNumberList.tolist()
    ##------------------ Order Items von DB Laden ------------------##
    dfOrderItems = SQL.sql_datenTabelleLaden('business_depotDEBYKN-DepotDEBYKNOrderItems')
    #------------------ Stammdaten von DB Laden ------------------#
    dfStammdaten = SQL.sql_datenTabelleLaden('data_materialmaster-MaterialMasterUnitOfMeasures')
    return dfOrderItems, dfOrder, dfStammdaten


###------------------  Update Funktionen  ------------------###

def start_Update_14TageTabelle():

    '''Startet das Programm mit den übergebenen Daten'''

    end_date = datetime.date.today()
    end_date = end_date + datetime.timedelta(days=5)
    start_date = datetime.date.today()
    start_date = start_date - datetime.timedelta(days=14)
    print(start_date)
    print('ende')
    print(end_date)

    dfOrderItems, dfOrder, dfStammdaten = loadTablesFromDB_byDateAndFilterDN(start_date, end_date)

    dfLabel = SQL.sql_datenLadenDatum(start_date, end_date ,SQL.tabelleSSCCLabel,'CreatedTimestamp')

    dfStammdaten = agg_stammdatenErweiterung(dfStammdaten)

    dfOrderItems = agg_berechne_DFOrderItems(dfOrderItems, dfStammdaten, dfOrder)

    dfOrderItems = agg_oderDatenItemsAndLabel(dfOrderItems, dfLabel)

    # Update der Datenbank UpdateTime
    dftime = pd.DataFrame({'time':[datetime.datetime.now()]})
    dftime['time'] = dftime['time'] + datetime.timedelta(hours=2)
    # SQL.trunk_Update('prod_KundenbestellungenUpdateTime',dftime)
    # ###------------------  Update Funktionen  ------------------###
    # SQL.trunk_Update('prod_Kundenbestellungen_14days',dfOrderItems)

    ########### TEste neue DB Version ############
    from src.SQLn import verbinder, load_table, update_table, truncate_table_and_load
    with verbinder() as conn:
        truncate_table_and_load(conn, 'prod_Kundenbestellungen_14days', dfOrderItems)
        truncate_table_and_load(conn, 'prod_KundenbestellungenUpdateTime', dftime)


import datetime

def start_Update_GesamtzeitraumDepot():
    #from src.SQLn import verbinder, load_table, update_table, truncate_table_and_load

    print(f"{datetime.datetime.now()} - Starting loading data from DB")
    dfOrderItems, dfOrder, dfStammdaten = loadAllDataFromDB()
    print(f"{datetime.datetime.now()} - Finished loading data from DB")

    print(f"{datetime.datetime.now()} - Starting loading data table 'business_depotDEBYKN-DepotOrderDEBYKN_SSCCs'")
    dfLabel = SQL.sql_datenTabelleLaden('business_depotDEBYKN-DepotOrderDEBYKN_SSCCs')
    print(f"{datetime.datetime.now()} - Finished loading data table 'business_depotDEBYKN-DepotOrderDEBYKN_SSCCs'")

    print(f"{datetime.datetime.now()} - Starting extending stammdaten")
    dfStammdaten = agg_stammdatenErweiterung(dfStammdaten)
    print(f"{datetime.datetime.now()} - Finished extending stammdaten")

    print(f"{datetime.datetime.now()} - Starting calculating order items")
    dfOrderItems = agg_berechne_DFOrderItems(dfOrderItems, dfStammdaten, dfOrder)
    print(f"{datetime.datetime.now()} - Finished calculating order items")

    print(f"{datetime.datetime.now()} - Starting combining order items and label")
    dfOrderItems = agg_oderDatenItemsAndLabel(dfOrderItems, dfLabel)
    print(f"{datetime.datetime.now()} - Finished combining order items and label")

    print(f"{datetime.datetime.now()} - Starting saving table to SQL")
    save_table_to_SQL(dfOrderItems, 'prod_Kundenbestellungen_test')
    print(f"{datetime.datetime.now()} - Finished saving table to SQL")
    #SQL.sql_createTable('prod_Kundenbestellungen',dfOrderItems)
    


    # with verbinder() as conn:
    #     truncate_table_and_load(conn, 'prod_Kundenbestellungen_14days', dfOrderItems)
        

